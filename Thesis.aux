\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*{\memsetcounter}[2]{}
\catcode `"\active 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{Acknowledgments}{ii}{chapter*.1}}
\citation{nirkin2018_faceswap}
\citation{egger_paper}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{Abstract}{iii}{chapter*.2}}
\@writefile{toc}{\vspace  {2em}}
\citation{BFM2017}
\citation{nirkin2018_faceswap}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {1}Introduction}{1}{chapter.3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Artificial neural networks}{1}{section.4}}
\citation{mcculloch}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces An example of an classical Convolutional Neural Network (CNN). After a certain number of convolutions, a pooling layer extracts the most important information of the image and writes it into the next layer. That is why the picture is getting smaller and smaller until just a vector is left. In our case (FCN) the picture is up sampled again to the original size.}}{2}{figure.5}}
\newlabel{fig:chap1:classicalCNN}{{\M@TitleReference {1.1}{An example of an classical Convolutional Neural Network (CNN). After a certain number of convolutions, a pooling layer extracts the most important information of the image and writes it into the next layer. That is why the picture is getting smaller and smaller until just a vector is left. In our case (FCN) the picture is up sampled again to the original size.}}{2}{An example of an classical Convolutional Neural Network (CNN). After a certain number of convolutions, a pooling layer extracts the most important information of the image and writes it into the next layer. That is why the picture is getting smaller and smaller until just a vector is left. In our case (FCN) the picture is up sampled again to the original size}{figure.5}{}}
\newlabel{fig:chap1:classicalCNN@cref}{{[figure][1][1]1.1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Caption for LOF}}{2}{figure.6}}
\newlabel{fig:test1}{{\M@TitleReference {1.2}{Caption for LOF}}{2}{Caption for LOF}{figure.6}{}}
\newlabel{fig:test1@cref}{{[figure][2][1]1.2}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Adjustment of the edgeweights}{2}{section.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces A simple neural network consisting of three layers. Neurons $\pi _1$ and $\pi _2$ are in the input layer. $\pi _3$ and $\pi _4$ make up the only hidden layer and $\pi _5$ is in the output layer. Each neuron sums up the input signals ($net\pi _i$), applies an activation function to it ($\sigma $) and forwards the output of this function as its own signal ($out\pi _i$). Mostly a sigmoid function is chosen as the activation function (right lower corner). The edgeweights are annotated with $\omega _i$.}}{3}{figure.9}}
\newlabel{fig:backpropagation}{{\M@TitleReference {1.3}{A simple neural network consisting of three layers. Neurons $\pi _1$ and $\pi _2$ are in the input layer. $\pi _3$ and $\pi _4$ make up the only hidden layer and $\pi _5$ is in the output layer. Each neuron sums up the input signals ($net\pi _i$), applies an activation function to it ($\sigma $) and forwards the output of this function as its own signal ($out\pi _i$). Mostly a sigmoid function is chosen as the activation function (right lower corner). The edgeweights are annotated with $\omega _i$.}}{3}{A simple neural network consisting of three layers. Neurons $\pi _1$ and $\pi _2$ are in the input layer. $\pi _3$ and $\pi _4$ make up the only hidden layer and $\pi _5$ is in the output layer. Each neuron sums up the input signals ($net\pi _i$), applies an activation function to it ($\sigma $) and forwards the output of this function as its own signal ($out\pi _i$). Mostly a sigmoid function is chosen as the activation function (right lower corner). The edgeweights are annotated with $\omega _i$}{figure.9}{}}
\newlabel{fig:backpropagation@cref}{{[figure][3][1]1.3}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}A simple claculation example (on Figure \ref  {fig:backpropagation})}{3}{subsection.10}}
\newlabel{subs:Example}{{\M@TitleReference {1.2.1}{A simple claculation example (on Figure \ref  {fig:backpropagation})}}{3}{A simple claculation example (on Figure \ref {fig:backpropagation})}{subsection.10}{}}
\newlabel{subs:Example@cref}{{[subsection][1][1,2]1.2.1}{3}}
\citation{nirkin2018_faceswap}
\citation{jlong}
\citation{ksimonyan}
\citation{jlong}
\citation{jlong}
\citation{nirkin2018_faceswap}
\citation{grundmann}
\citation{egger_paper}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}The network used}{5}{section.11}}
\newlabel{sec:theFCN}{{\M@TitleReference {1.3}{The network used}}{5}{The network used}{section.11}{}}
\newlabel{sec:theFCN@cref}{{[section][3][1]1.3}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Related Work}{5}{section.13}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces In the lower-left corner, the 16 layers of the well known VGGnet are shown. In the top-right, you can see the meaning of the '8s' term of the FCN-Name. It means that the resulting image has to be 8x upsampled, to get an image which is in size equal to the input image. J. Long et al \cite  {jlong} take the network and transform the fully connected layers into convolution layers (bottom-right).}}{6}{figure.12}}
\citation{Uricar}
\citation{Uricar}
\citation{egger_paper}
\citation{SaitoEtAl}
\citation{MorelForster}
\citation{nirkin2018_faceswap}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces This picture shows the development of the labels after 0, 10 and 20 iterations. Striking in this sample image are not only the eyes as mentioned before but also the shadow of the nose, which is first segmented as a background. Only after a certain number of iterations these errors are partially recognized and provided with the correct label.}}{7}{figure.14}}
\newlabel{fig:iterations}{{\M@TitleReference {1.5}{This picture shows the development of the labels after 0, 10 and 20 iterations. Striking in this sample image are not only the eyes as mentioned before but also the shadow of the nose, which is first segmented as a background. Only after a certain number of iterations these errors are partially recognized and provided with the correct label.}}{7}{This picture shows the development of the labels after 0, 10 and 20 iterations. Striking in this sample image are not only the eyes as mentioned before but also the shadow of the nose, which is first segmented as a background. Only after a certain number of iterations these errors are partially recognized and provided with the correct label}{figure.14}{}}
\newlabel{fig:iterations@cref}{{[figure][5][1]1.5}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Expectations of the FCN}{7}{section.17}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces caption without footnote, for lof}}{8}{figure.15}}
\newlabel{fig:EGGER's_method}{{\M@TitleReference {1.6}{caption without footnote, for lof}}{8}{caption without footnote, for lof}{figure.15}{}}
\newlabel{fig:EGGER's_method@cref}{{[figure][6][1]1.6}{8}}
\citation{cofw}
\citation{LFW_dataset}
\citation{nirkin2018_faceswap}
\citation{egger_paper}
\citation{egger_paper}
\citation{nirkin2018_faceswap}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {2}Evaluation}{9}{chapter.18}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Evaluation on Datasets}{9}{section.19}}
\newlabel{sec:EvaluationOnDatasets}{{\M@TitleReference {2.1}{Evaluation on Datasets}}{9}{Evaluation on Datasets}{section.19}{}}
\newlabel{sec:EvaluationOnDatasets@cref}{{[section][1][2]2.1}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}COFW}{9}{subsection.20}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces 18 images of the COFW Dataset overlayd with the FCN output (in red). The segmentation results are very similar to those on \href  {https://github.com/YuvalNirkin/face_segmentation}{Nirkin's github page}.}}{10}{figure.21}}
\newlabel{fig:chap2:myMatrix}{{\M@TitleReference {2.1}{18 images of the COFW Dataset overlayd with the FCN output (in red). The segmentation results are very similar to those on \href  {https://github.com/YuvalNirkin/face_segmentation}{Nirkin's github page}.}}{10}{18 images of the COFW Dataset overlayd with the FCN output (in red). The segmentation results are very similar to those on \href {https://github.com/YuvalNirkin/face_segmentation}{Nirkin's github page}}{figure.21}{}}
\newlabel{fig:chap2:myMatrix@cref}{{[figure][1][2]2.1}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Exactly the same images as in Figure \ref  {fig:chap2:myMatrix}, but this time with the (final) segmentation of the occlusion-aware method of Egger et al. \cite  {egger_paper}. Often the eyes are not segmented or the segmentation includes skin other than the face (eg. hands).}}{10}{figure.22}}
\newlabel{fig:chap2:myMatrix_EGGER}{{\M@TitleReference {2.2}{Exactly the same images as in Figure \ref  {fig:chap2:myMatrix}, but this time with the (final) segmentation of the occlusion-aware method of Egger et al. \cite  {egger_paper}. Often the eyes are not segmented or the segmentation includes skin other than the face (eg. hands).}}{10}{Exactly the same images as in Figure \ref {fig:chap2:myMatrix}, but this time with the (final) segmentation of the occlusion-aware method of Egger et al. \cite {egger_paper}. Often the eyes are not segmented or the segmentation includes skin other than the face (eg. hands)}{figure.22}{}}
\newlabel{fig:chap2:myMatrix_EGGER@cref}{{[figure][2][2]2.2}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Parts-LFW}{10}{subsection.29}}
\citation{LFW_dataset}
\citation{LFW_dataset}
\citation{parametric}
\citation{nirkin2018_faceswap}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Tuples of facial images. In every tuple, the first image shows the fit with the mask of the algorithm of Egger et al. itself (Figure \ref  {fig:chap2:myMatrix_EGGER}). The second shows the fit with the FCN mask which are depicted in Figure \ref  {fig:chap2:myMatrix}.}}{11}{figure.23}}
\newlabel{fig:chap2:COFW_Fits}{{\M@TitleReference {2.3}{Tuples of facial images. In every tuple, the first image shows the fit with the mask of the algorithm of Egger et al. itself (Figure \ref  {fig:chap2:myMatrix_EGGER}). The second shows the fit with the FCN mask which are depicted in Figure \ref  {fig:chap2:myMatrix}.}}{11}{Tuples of facial images. In every tuple, the first image shows the fit with the mask of the algorithm of Egger et al. itself (Figure \ref {fig:chap2:myMatrix_EGGER}). The second shows the fit with the FCN mask which are depicted in Figure \ref {fig:chap2:myMatrix}}{figure.23}{}}
\newlabel{fig:chap2:COFW_Fits@cref}{{[figure][3][2]2.3}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Evaluation on Synthetic-Data}{11}{section.31}}
\newlabel{fig:drew:sf1}{{2.4(a)}{12}{Subfigure 2.4(a)\relax }{subfigure.24}{}}
\newlabel{sub@fig:drew:sf1}{{(a)}{12}{Subfigure 2.4(a)\relax }{subfigure.24}{}}
\newlabel{fig:drew:sf1@cref}{{[subfigure][1][2,4]2.4(a)}{12}}
\newlabel{fig:drew:sf2}{{2.4(b)}{12}{Subfigure 2.4(b)\relax }{subfigure.25}{}}
\newlabel{sub@fig:drew:sf2}{{(b)}{12}{Subfigure 2.4(b)\relax }{subfigure.25}{}}
\newlabel{fig:drew:sf2@cref}{{[subfigure][2][2,4]2.4(b)}{12}}
\newlabel{fig:ali:sf3}{{2.4(c)}{12}{Subfigure 2.4(c)\relax }{subfigure.26}{}}
\newlabel{sub@fig:ali:sf3}{{(c)}{12}{Subfigure 2.4(c)\relax }{subfigure.26}{}}
\newlabel{fig:ali:sf3@cref}{{[subfigure][3][2,4]2.4(c)}{12}}
\newlabel{fig:ali:sf4}{{2.4(d)}{12}{Subfigure 2.4(d)\relax }{subfigure.27}{}}
\newlabel{sub@fig:ali:sf4}{{(d)}{12}{Subfigure 2.4(d)\relax }{subfigure.27}{}}
\newlabel{fig:ali:sf4@cref}{{[subfigure][4][2,4]2.4(d)}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Plots of four Turing machines}}{12}{figure.28}}
\newlabel{fig:tm}{{\M@TitleReference {2.4}{Plots of four Turing machines}}{12}{Plots of four Turing machines}{figure.28}{}}
\newlabel{fig:tm@cref}{{[figure][4][2]2.4}{12}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces An facial-image with the segmentation of the FCN highlited in red}}{12}{figure.28}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces The provided ground-truth segmentation of the image \ref {fig:drew:sf1} overlaid with the mask of the FCN (red)}}{12}{figure.28}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces An facial-image with the segmentation of the FCN highlited in red}}{12}{figure.28}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces The provided ground-truth segmentation of the image \ref {fig:ali:sf3} overlaid with the mask of the FCN (red)}}{12}{figure.28}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces The averages over the 447 images of the Parts-LFW evaluation set of \cite  {LFW_dataset}. The FCN recognizes (almost) only pixels, which belong to the face (little false positives). By reducing from 500 to 447 images, we were able to reduce them. Unfortunately, there are many false negatives (skin pixels labeled as background).}}{12}{figure.30}}
\newlabel{fig:Parts-LFW}{{\M@TitleReference {2.5}{The averages over the 447 images of the Parts-LFW evaluation set of \cite  {LFW_dataset}. The FCN recognizes (almost) only pixels, which belong to the face (little false positives). By reducing from 500 to 447 images, we were able to reduce them. Unfortunately, there are many false negatives (skin pixels labeled as background).}}{12}{The averages over the 447 images of the Parts-LFW evaluation set of \cite {LFW_dataset}. The FCN recognizes (almost) only pixels, which belong to the face (little false positives). By reducing from 500 to 447 images, we were able to reduce them. Unfortunately, there are many false negatives (skin pixels labeled as background)}{figure.30}{}}
\newlabel{fig:Parts-LFW@cref}{{[figure][5][2]2.5}{12}}
\citation{parametric}
\citation{parametric}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Five examples of the synthetic face images. The same face is shown with yaw angles $-45$\textdegree , $-25$\textdegree , $0$\textdegree , $25$\textdegree , and $45$\textdegree . The occlusion is randomly choosen and in a random orientation and position.}}{13}{figure.32}}
\newlabel{fig:syntheticData_samples}{{\M@TitleReference {2.6}{Five examples of the synthetic face images. The same face is shown with yaw angles $-45$\textdegree , $-25$\textdegree , $0$\textdegree , $25$\textdegree , and $45$\textdegree . The occlusion is randomly choosen and in a random orientation and position.}}{13}{Five examples of the synthetic face images. The same face is shown with yaw angles $-45$\textdegree , $-25$\textdegree , $0$\textdegree , $25$\textdegree , and $45$\textdegree . The occlusion is randomly choosen and in a random orientation and position}{figure.32}{}}
\newlabel{fig:syntheticData_samples@cref}{{[figure][6][2]2.6}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Dependence of the Euler angles}{13}{subsection.33}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}random boxes as occlusions}{13}{subsection.35}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces In the plots on the top row we see the segmetation accuracy in percent (on the y-axis) for every single image (with face angle from $-50$\textdegree to $50$\textdegree on the x-axis). The point cloud is approximated by a quadratic function via a least squares fit (red curve / $f(x)$). The first parameter of this function determines the opening angle ($p_1$). In the bottom row the colors indicate the segmentation accuracy. The brighter the color, the better the segmentation. In every plot, there is a cluster of high accuracy segmentations centered in the origin. The angle on whose axis the cluster has the smaller extent is the more important of the two. We call an angle 'important', when a small change of this angle leads to a failure of the FCN.}}{14}{figure.34}}
\newlabel{fig:evaluation_angles}{{\M@TitleReference {2.7}{In the plots on the top row we see the segmetation accuracy in percent (on the y-axis) for every single image (with face angle from $-50$\textdegree to $50$\textdegree on the x-axis). The point cloud is approximated by a quadratic function via a least squares fit (red curve / $f(x)$). The first parameter of this function determines the opening angle ($p_1$). In the bottom row the colors indicate the segmentation accuracy. The brighter the color, the better the segmentation. In every plot, there is a cluster of high accuracy segmentations centered in the origin. The angle on whose axis the cluster has the smaller extent is the more important of the two. We call an angle 'important', when a small change of this angle leads to a failure of the FCN.}}{14}{In the plots on the top row we see the segmetation accuracy in percent (on the y-axis) for every single image (with face angle from $-50$\textdegree to $50$\textdegree on the x-axis). The point cloud is approximated by a quadratic function via a least squares fit (red curve / $f(x)$). The first parameter of this function determines the opening angle ($p_1$). In the bottom row the colors indicate the segmentation accuracy. The brighter the color, the better the segmentation. In every plot, there is a cluster of high accuracy segmentations centered in the origin. The angle on whose axis the cluster has the smaller extent is the more important of the two. We call an angle 'important', when a small change of this angle leads to a failure of the FCN}{figure.34}{}}
\newlabel{fig:evaluation_angles@cref}{{[figure][7][2]2.7}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Based on these images, we can see that the roll angle (rotation) is the most sensitive, followed by the pitch angle (tilt), where the segmentation works better on positive angles than on negative ones. The most stable detection is at the yaw angle. It has the least influence on the segmentation.}}{14}{figure.36}}
\newlabel{fig:angle_table}{{\M@TitleReference {2.8}{Based on these images, we can see that the roll angle (rotation) is the most sensitive, followed by the pitch angle (tilt), where the segmentation works better on positive angles than on negative ones. The most stable detection is at the yaw angle. It has the least influence on the segmentation.}}{14}{Based on these images, we can see that the roll angle (rotation) is the most sensitive, followed by the pitch angle (tilt), where the segmentation works better on positive angles than on negative ones. The most stable detection is at the yaw angle. It has the least influence on the segmentation}{figure.36}{}}
\newlabel{fig:angle_table@cref}{{[figure][8][2]2.8}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces The color of each grid cell indicates the accuracy of the segmentation of the FCN on a set of faces turned by the corresponding angle and occluded with a square, so that the corresponding amount (on the x-axis) of the face is hidden. The brighter the color, the better the segmentation. On each plot, we would expect to see a triangle pointing to the right. This means that the combination of a large angle and a large occlusion make the face even more unsegmentable.}}{15}{figure.37}}
\newlabel{fig:occVal40}{{\M@TitleReference {2.9}{The color of each grid cell indicates the accuracy of the segmentation of the FCN on a set of faces turned by the corresponding angle and occluded with a square, so that the corresponding amount (on the x-axis) of the face is hidden. The brighter the color, the better the segmentation. On each plot, we would expect to see a triangle pointing to the right. This means that the combination of a large angle and a large occlusion make the face even more unsegmentable.}}{15}{The color of each grid cell indicates the accuracy of the segmentation of the FCN on a set of faces turned by the corresponding angle and occluded with a square, so that the corresponding amount (on the x-axis) of the face is hidden. The brighter the color, the better the segmentation. On each plot, we would expect to see a triangle pointing to the right. This means that the combination of a large angle and a large occlusion make the face even more unsegmentable}{figure.37}{}}
\newlabel{fig:occVal40@cref}{{[figure][9][2]2.9}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces This plot shows the outcome of a similar expreiment as snown in Figure \ref  {fig:occVal40} with less resolution. All the angles (yaw, pitch and roll) range from $-90$\textdegree to $90$ \textdegree . The scale on the "\%-occlusion" stays the same as in Figure \ref  {fig:occVal40} We can clearly see the limits of the FCN even with a occlusion of 2\%! Very interesting is the hard transition from good segmentations to bad segmentations in the two right plots.}}{15}{figure.38}}
\newlabel{fig:occVal90}{{\M@TitleReference {2.10}{This plot shows the outcome of a similar expreiment as snown in Figure \ref  {fig:occVal40} with less resolution. All the angles (yaw, pitch and roll) range from $-90$\textdegree to $90$ \textdegree . The scale on the "\%-occlusion" stays the same as in Figure \ref  {fig:occVal40} We can clearly see the limits of the FCN even with a occlusion of 2\%! Very interesting is the hard transition from good segmentations to bad segmentations in the two right plots.}}{15}{This plot shows the outcome of a similar expreiment as snown in Figure \ref {fig:occVal40} with less resolution. All the angles (yaw, pitch and roll) range from $-90$\textdegree to $90$ \textdegree . The scale on the "\%-occlusion" stays the same as in Figure \ref {fig:occVal40} We can clearly see the limits of the FCN even with a occlusion of 2\%! Very interesting is the hard transition from good segmentations to bad segmentations in the two right plots}{figure.38}{}}
\newlabel{fig:occVal90@cref}{{[figure][10][2]2.10}{15}}
\citation{parametric}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Parametric-Face-Image-Generator}{16}{section.39}}
\citation{egger_paper}
\citation{BFM2017}
\citation{BlanzVetter}
\citation{parametric}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {3}Evaluation of the Fitting with the Segmentation of the FCN}{17}{chapter.40}}
\newlabel{fig:chap3:lms:1}{{3.1(a)}{18}{Subfigure 3.1(a)\relax }{subfigure.41}{}}
\newlabel{sub@fig:chap3:lms:1}{{(a)}{18}{Subfigure 3.1(a)\relax }{subfigure.41}{}}
\newlabel{fig:chap3:lms:1@cref}{{[subfigure][1][3,1]3.1(a)}{18}}
\newlabel{fig:chap3:lms:2}{{3.1(b)}{18}{Subfigure 3.1(b)\relax }{subfigure.42}{}}
\newlabel{sub@fig:chap3:lms:2}{{(b)}{18}{Subfigure 3.1(b)\relax }{subfigure.42}{}}
\newlabel{fig:chap3:lms:2@cref}{{[subfigure][2][3,1]3.1(b)}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces The original landmarks (green dots) and the landmark which had to be disabled because of the occlusion (red dots)}}{18}{figure.43}}
\newlabel{fig:chap3:lms}{{\M@TitleReference {3.1}{The original landmarks (green dots) and the landmark which had to be disabled because of the occlusion (red dots)}}{18}{The original landmarks (green dots) and the landmark which had to be disabled because of the occlusion (red dots)}{figure.43}{}}
\newlabel{fig:chap3:lms@cref}{{[figure][1][3]3.1}{18}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces A facial image of the Parametric-Face-Image-Generator with all landmarks activated.}}{18}{figure.43}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces The same image as in \ref {fig:chap3:lms:1} but with an occlusion and two underlying landmarks which are disabled because they're not visible anymore.}}{18}{figure.43}}
\citation{egger_paper}
\citation{egger_paper}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Evaluation on a tailored face}{19}{section.44}}
\newlabel{fig:chap3:hands_original}{{3.2(a)}{19}{Subfigure 3.2(a)\relax }{subfigure.45}{}}
\newlabel{sub@fig:chap3:hands_original}{{(a)}{19}{Subfigure 3.2(a)\relax }{subfigure.45}{}}
\newlabel{fig:chap3:hands_original@cref}{{[subfigure][1][3,2]3.2(a)}{19}}
\newlabel{fig:chap3:hands_occluded}{{3.2(b)}{19}{Subfigure 3.2(b)\relax }{subfigure.46}{}}
\newlabel{sub@fig:chap3:hands_occluded}{{(b)}{19}{Subfigure 3.2(b)\relax }{subfigure.46}{}}
\newlabel{fig:chap3:hands_occluded@cref}{{[subfigure][2][3,2]3.2(b)}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces These pictures show the faces that should be modeled with different masks. We fit with the method Egger et al. \cite  {egger_paper} from \Cref  {fig:chap3:hands_occluded} a face as similar as possible to the face in \Cref  {fig:chap3:hands_original}.}}{19}{figure.47}}
\newlabel{fig:chap3:hands_PARAMETRIC}{{\M@TitleReference {3.2}{These pictures show the faces that should be modeled with different masks. We fit with the method Egger et al. \cite  {egger_paper} from \Cref  {fig:chap3:hands_occluded} a face as similar as possible to the face in \Cref  {fig:chap3:hands_original}.}}{19}{These pictures show the faces that should be modeled with different masks. We fit with the method Egger et al. \cite {egger_paper} from \Cref {fig:chap3:hands_occluded} a face as similar as possible to the face in \Cref {fig:chap3:hands_original}}{figure.47}{}}
\newlabel{fig:chap3:hands_PARAMETRIC@cref}{{[figure][2][3]3.2}{19}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces original facial image}}{19}{figure.47}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces facial image with occlusion}}{19}{figure.47}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces In the top row are the different segmentations we use for our experiments. The segmentation of Egger et al. (second image from left) was calculated iteratively. Given is only the final mask. In the second row are the particular fits, when the above mask is used as segmentation. You can see that the fits without any mask (NO MASK) and the fit with the mask according to Egger et al. (EGGER) are far away from the true face depicted in Figure \ref  {fig:chap3:hands_original}. However, the fit with ground truth mask of the Parametric-Face-Image-Generator (GROUDTRUTH) and the one with the FCN-Segmentation (FCN) come very close to the original.}}{20}{figure.48}}
\newlabel{fig:chap3:zlabelsandfits}{{\M@TitleReference {3.3}{In the top row are the different segmentations we use for our experiments. The segmentation of Egger et al. (second image from left) was calculated iteratively. Given is only the final mask. In the second row are the particular fits, when the above mask is used as segmentation. You can see that the fits without any mask (NO MASK) and the fit with the mask according to Egger et al. (EGGER) are far away from the true face depicted in Figure \ref  {fig:chap3:hands_original}. However, the fit with ground truth mask of the Parametric-Face-Image-Generator (GROUDTRUTH) and the one with the FCN-Segmentation (FCN) come very close to the original.}}{20}{In the top row are the different segmentations we use for our experiments. The segmentation of Egger et al. (second image from left) was calculated iteratively. Given is only the final mask. In the second row are the particular fits, when the above mask is used as segmentation. You can see that the fits without any mask (NO MASK) and the fit with the mask according to Egger et al. (EGGER) are far away from the true face depicted in Figure \ref {fig:chap3:hands_original}. However, the fit with ground truth mask of the Parametric-Face-Image-Generator (GROUDTRUTH) and the one with the FCN-Segmentation (FCN) come very close to the original}{figure.48}{}}
\newlabel{fig:chap3:zlabelsandfits@cref}{{[figure][3][3]3.3}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces The first three plots show the errors of the first 50 shape, color and expression parameters of the Basel Face Model(in standard deviations). The next three show the errors af the Euler Angles in radian. The 'EnvironmentMap'-plot shows the illumination chosen by all methods. In the last plot we see the unnormalized posterior-probability, with which a MCMC model was accepted.}}{21}{figure.49}}
\newlabel{fig:chap3:plot_hands_setup1}{{\M@TitleReference {3.4}{The first three plots show the errors of the first 50 shape, color and expression parameters of the Basel Face Model(in standard deviations). The next three show the errors af the Euler Angles in radian. The 'EnvironmentMap'-plot shows the illumination chosen by all methods. In the last plot we see the unnormalized posterior-probability, with which a MCMC model was accepted.}}{21}{The first three plots show the errors of the first 50 shape, color and expression parameters of the Basel Face Model(in standard deviations). The next three show the errors af the Euler Angles in radian. The 'EnvironmentMap'-plot shows the illumination chosen by all methods. In the last plot we see the unnormalized posterior-probability, with which a MCMC model was accepted}{figure.49}{}}
\newlabel{fig:chap3:plot_hands_setup1@cref}{{[figure][4][3]3.4}{21}}
\newlabel{fig:chap3:hands_setting2_original}{{3.5(a)}{22}{Subfigure 3.5(a)\relax }{subfigure.50}{}}
\newlabel{sub@fig:chap3:hands_setting2_original}{{(a)}{22}{Subfigure 3.5(a)\relax }{subfigure.50}{}}
\newlabel{fig:chap3:hands_setting2_original@cref}{{[subfigure][1][3,5]3.5(a)}{22}}
\newlabel{fig:chap3:hands_setting2_occluded}{{3.5(b)}{22}{Subfigure 3.5(b)\relax }{subfigure.51}{}}
\newlabel{sub@fig:chap3:hands_setting2_occluded}{{(b)}{22}{Subfigure 3.5(b)\relax }{subfigure.51}{}}
\newlabel{fig:chap3:hands_setting2_occluded@cref}{{[subfigure][2][3,5]3.5(b)}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces These pictures are different from the ones in Figure \ref  {fig:chap3:hands_PARAMETRIC} because we now use the 'bfm' version of the Basel Face Model which contains ears and neck. The fitting algorithm takes \ref  {fig:chap3:hands_setting2_occluded} as input and 'tries' to approximate \ref  {fig:chap3:hands_setting2_original}.}}{22}{figure.52}}
\newlabel{fig:chap3:hands_setting2_PARAMETRIC}{{\M@TitleReference {3.5}{These pictures are different from the ones in Figure \ref  {fig:chap3:hands_PARAMETRIC} because we now use the 'bfm' version of the Basel Face Model which contains ears and neck. The fitting algorithm takes \ref  {fig:chap3:hands_setting2_occluded} as input and 'tries' to approximate \ref  {fig:chap3:hands_setting2_original}.}}{22}{These pictures are different from the ones in Figure \ref {fig:chap3:hands_PARAMETRIC} because we now use the 'bfm' version of the Basel Face Model which contains ears and neck. The fitting algorithm takes \ref {fig:chap3:hands_setting2_occluded} as input and 'tries' to approximate \ref {fig:chap3:hands_setting2_original}}{figure.52}{}}
\newlabel{fig:chap3:hands_setting2_PARAMETRIC@cref}{{[figure][5][3]3.5}{22}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces original facial image}}{22}{figure.52}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces facial image with occlusion}}{22}{figure.52}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Due to the over-segmentation by Egger, a clear difference in the error of the 'color' parameters can be seen. The mask of the FCN models the color significantly better.}}{22}{figure.53}}
\newlabel{fig:chap3:zlabelsandfits_setting2}{{\M@TitleReference {3.6}{Due to the over-segmentation by Egger, a clear difference in the error of the 'color' parameters can be seen. The mask of the FCN models the color significantly better.}}{22}{Due to the over-segmentation by Egger, a clear difference in the error of the 'color' parameters can be seen. The mask of the FCN models the color significantly better}{figure.53}{}}
\newlabel{fig:chap3:zlabelsandfits_setting2@cref}{{[figure][6][3]3.6}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Due to the over-segmentation by Egger, a clear difference in the error of the 'color' parameters can be seen. The mask of the FCN models the color significantly better.}}{23}{figure.54}}
\newlabel{fig:chap3:plot_hands_setup2}{{\M@TitleReference {3.7}{Due to the over-segmentation by Egger, a clear difference in the error of the 'color' parameters can be seen. The mask of the FCN models the color significantly better.}}{23}{Due to the over-segmentation by Egger, a clear difference in the error of the 'color' parameters can be seen. The mask of the FCN models the color significantly better}{figure.54}{}}
\newlabel{fig:chap3:plot_hands_setup2@cref}{{[figure][7][3]3.7}{23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Runtime}{24}{subsection.55}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Comparison of the Wall-Clock Time for the fitting process. The times were measured with the tailored 'face12' mask and the 'bfm' rendering.}}{24}{figure.56}}
\newlabel{fig:chap3:times}{{\M@TitleReference {3.8}{Comparison of the Wall-Clock Time for the fitting process. The times were measured with the tailored 'face12' mask and the 'bfm' rendering.}}{24}{Comparison of the Wall-Clock Time for the fitting process. The times were measured with the tailored 'face12' mask and the 'bfm' rendering}{figure.56}{}}
\newlabel{fig:chap3:times@cref}{{[figure][8][3]3.8}{24}}
\citation{egger_paper}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {4}Integration of the FCN into the original work of Egger et al.}{25}{chapter.57}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces This example illustrates a major advantage and a disadvantage of Egger's approach. The FCN can't find the thin glass, but segments the eyes while Egger does not.}}{26}{figure.58}}
\newlabel{fig:chap4:harry}{{\M@TitleReference {4.1}{This example illustrates a major advantage and a disadvantage of Egger's approach. The FCN can't find the thin glass, but segments the eyes while Egger does not.}}{26}{This example illustrates a major advantage and a disadvantage of Egger's approach. The FCN can't find the thin glass, but segments the eyes while Egger does not}{figure.58}{}}
\newlabel{fig:chap4:harry@cref}{{[figure][1][4]4.1}{26}}
\newlabel{fig:chap4:bsp1_mask_FCN}{{4.2(a)}{27}{Subfigure 4.2(a)\relax }{subfigure.59}{}}
\newlabel{sub@fig:chap4:bsp1_mask_FCN}{{(a)}{27}{Subfigure 4.2(a)\relax }{subfigure.59}{}}
\newlabel{fig:chap4:bsp1_mask_FCN@cref}{{[subfigure][1][4,2]4.2(a)}{27}}
\newlabel{fig:chap4:bsp1_mask_EGGER}{{4.2(b)}{27}{Subfigure 4.2(b)\relax }{subfigure.60}{}}
\newlabel{sub@fig:chap4:bsp1_mask_EGGER}{{(b)}{27}{Subfigure 4.2(b)\relax }{subfigure.60}{}}
\newlabel{fig:chap4:bsp1_mask_EGGER@cref}{{[subfigure][2][4,2]4.2(b)}{27}}
\newlabel{fig:chap4:bsp1_mask_combined}{{4.2(c)}{27}{Subfigure 4.2(c)\relax }{subfigure.61}{}}
\newlabel{sub@fig:chap4:bsp1_mask_combined}{{(c)}{27}{Subfigure 4.2(c)\relax }{subfigure.61}{}}
\newlabel{fig:chap4:bsp1_mask_combined@cref}{{[subfigure][3][4,2]4.2(c)}{27}}
\newlabel{fig:chap4:bsp1_fit_combined}{{4.2(d)}{27}{Subfigure 4.2(d)\relax }{subfigure.62}{}}
\newlabel{sub@fig:chap4:bsp1_fit_combined}{{(d)}{27}{Subfigure 4.2(d)\relax }{subfigure.62}{}}
\newlabel{fig:chap4:bsp1_fit_combined@cref}{{[subfigure][4][4,2]4.2(d)}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces An example of the combination of the two masks. Figure \ref  {fig:chap4:bsp1_mask_FCN} shows the segmentation of the FCN while Figure \ref  {fig:chap4:bsp1_mask_EGGER} shows the segmentation by Egger et al. The combination is depicted in Figure \ref  {fig:chap4:bsp1_mask_combined}. The target image for this example is the same as in Figure \ref  {fig:chap3:hands_PARAMETRIC}. We see our fears confirmed and that the initial segmentation only makes a tiny difference. Figure \ref  {fig:chap4:bsp1_fit_combined} shows the resulting fit with the combined mask.}}{27}{figure.63}}
\newlabel{fig:chap4:bsp1}{{\M@TitleReference {4.2}{An example of the combination of the two masks. Figure \ref  {fig:chap4:bsp1_mask_FCN} shows the segmentation of the FCN while Figure \ref  {fig:chap4:bsp1_mask_EGGER} shows the segmentation by Egger et al. The combination is depicted in Figure \ref  {fig:chap4:bsp1_mask_combined}. The target image for this example is the same as in Figure \ref  {fig:chap3:hands_PARAMETRIC}. We see our fears confirmed and that the initial segmentation only makes a tiny difference. Figure \ref  {fig:chap4:bsp1_fit_combined} shows the resulting fit with the combined mask.}}{27}{An example of the combination of the two masks. Figure \ref {fig:chap4:bsp1_mask_FCN} shows the segmentation of the FCN while Figure \ref {fig:chap4:bsp1_mask_EGGER} shows the segmentation by Egger et al. The combination is depicted in Figure \ref {fig:chap4:bsp1_mask_combined}. The target image for this example is the same as in Figure \ref {fig:chap3:hands_PARAMETRIC}. We see our fears confirmed and that the initial segmentation only makes a tiny difference. Figure \ref {fig:chap4:bsp1_fit_combined} shows the resulting fit with the combined mask}{figure.63}{}}
\newlabel{fig:chap4:bsp1@cref}{{[figure][2][4]4.2}{27}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces initial mask of the FCN}}{27}{figure.63}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces segmentation of Egger et al.}}{27}{figure.63}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces combined segmentation}}{27}{figure.63}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces fit with the combined mask (Subfigure (c))}}{27}{figure.63}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces A comparison of the Basel Face Model parameters. In this plot the fits of egger and the fcn of Figure \ref  {fig:chap3:zlabelsandfits} and \ref  {fig:chap4:bsp1_fit_combined} are compared. Per parameter, only the first 5 dimensions are considered. In all considered parameters, the version with the combined mask has a lower error than the slower fit with the mask of Egger et al. alone!}}{27}{figure.64}}
\newlabel{fig:chap4:fit_comparison_1}{{\M@TitleReference {4.3}{A comparison of the Basel Face Model parameters. In this plot the fits of egger and the fcn of Figure \ref  {fig:chap3:zlabelsandfits} and \ref  {fig:chap4:bsp1_fit_combined} are compared. Per parameter, only the first 5 dimensions are considered. In all considered parameters, the version with the combined mask has a lower error than the slower fit with the mask of Egger et al. alone!}}{27}{A comparison of the Basel Face Model parameters. In this plot the fits of egger and the fcn of Figure \ref {fig:chap3:zlabelsandfits} and \ref {fig:chap4:bsp1_fit_combined} are compared. Per parameter, only the first 5 dimensions are considered. In all considered parameters, the version with the combined mask has a lower error than the slower fit with the mask of Egger et al. alone!}{figure.64}{}}
\newlabel{fig:chap4:fit_comparison_1@cref}{{[figure][3][4]4.3}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces The illuminations of the last example rendered on a sphere. It seems like the illumination with the FCN mask is dull and has no specular term (only ambient). However, the illumination with the combined mask is strongly based on illumination (a).}}{28}{figure.69}}
\newlabel{fig:chap4:bsp1_illumination}{{\M@TitleReference {4.4}{The illuminations of the last example rendered on a sphere. It seems like the illumination with the FCN mask is dull and has no specular term (only ambient). However, the illumination with the combined mask is strongly based on illumination (a).}}{28}{The illuminations of the last example rendered on a sphere. It seems like the illumination with the FCN mask is dull and has no specular term (only ambient). However, the illumination with the combined mask is strongly based on illumination (a)}{figure.69}{}}
\newlabel{fig:chap4:bsp1_illumination@cref}{{[figure][4][4]4.4}{28}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces Egger et al.}}{28}{figure.69}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces FCN}}{28}{figure.69}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces combination}}{28}{figure.69}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces groundtruth}}{28}{figure.69}}
\newlabel{fig:chap4:bsp2_mask_FCN}{{4.5(a)}{28}{Subfigure 4.5(a)\relax }{subfigure.70}{}}
\newlabel{sub@fig:chap4:bsp2_mask_FCN}{{(a)}{28}{Subfigure 4.5(a)\relax }{subfigure.70}{}}
\newlabel{fig:chap4:bsp2_mask_FCN@cref}{{[subfigure][1][4,5]4.5(a)}{28}}
\newlabel{fig:chap4:bsp2_mask_EGGER}{{4.5(b)}{28}{Subfigure 4.5(b)\relax }{subfigure.71}{}}
\newlabel{sub@fig:chap4:bsp2_mask_EGGER}{{(b)}{28}{Subfigure 4.5(b)\relax }{subfigure.71}{}}
\newlabel{fig:chap4:bsp2_mask_EGGER@cref}{{[subfigure][2][4,5]4.5(b)}{28}}
\newlabel{fig:chap4:bsp2_mask_combined}{{4.5(c)}{28}{Subfigure 4.5(c)\relax }{subfigure.72}{}}
\newlabel{sub@fig:chap4:bsp2_mask_combined}{{(c)}{28}{Subfigure 4.5(c)\relax }{subfigure.72}{}}
\newlabel{fig:chap4:bsp2_mask_combined@cref}{{[subfigure][3][4,5]4.5(c)}{28}}
\newlabel{fig:chap4:bsp2_fit_combined}{{4.5(d)}{28}{Subfigure 4.5(d)\relax }{subfigure.73}{}}
\newlabel{sub@fig:chap4:bsp2_fit_combined}{{(d)}{28}{Subfigure 4.5(d)\relax }{subfigure.73}{}}
\newlabel{fig:chap4:bsp2_fit_combined@cref}{{[subfigure][4][4,5]4.5(d)}{28}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces An example of the combination of the two masks. Figure \ref  {fig:chap4:bsp2_mask_FCN} shows the segmentation of the FCN while Figure \ref  {fig:chap4:bsp2_mask_EGGER} shows the segmentation by Egger et al. The combination is depicted in Figure \ref  {fig:chap4:bsp2_mask_combined}. The target image for this example is the same as in Figure \ref  {fig:chap3:hands_setting2_occluded}. Figure \ref  {fig:chap4:bsp2_fit_combined} shows the resulting fit with the combined mask.}}{28}{figure.74}}
\newlabel{fig:chap4:bsp2}{{\M@TitleReference {4.5}{An example of the combination of the two masks. Figure \ref  {fig:chap4:bsp2_mask_FCN} shows the segmentation of the FCN while Figure \ref  {fig:chap4:bsp2_mask_EGGER} shows the segmentation by Egger et al. The combination is depicted in Figure \ref  {fig:chap4:bsp2_mask_combined}. The target image for this example is the same as in Figure \ref  {fig:chap3:hands_setting2_occluded}. Figure \ref  {fig:chap4:bsp2_fit_combined} shows the resulting fit with the combined mask.}}{28}{An example of the combination of the two masks. Figure \ref {fig:chap4:bsp2_mask_FCN} shows the segmentation of the FCN while Figure \ref {fig:chap4:bsp2_mask_EGGER} shows the segmentation by Egger et al. The combination is depicted in Figure \ref {fig:chap4:bsp2_mask_combined}. The target image for this example is the same as in Figure \ref {fig:chap3:hands_setting2_occluded}. Figure \ref {fig:chap4:bsp2_fit_combined} shows the resulting fit with the combined mask}{figure.74}{}}
\newlabel{fig:chap4:bsp2@cref}{{[figure][5][4]4.5}{28}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces initial mask of the FCN}}{28}{figure.74}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces segmentation of Egger et al.}}{28}{figure.74}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces combined segmentation}}{28}{figure.74}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces fit with the combined mask (Subfigure (c))}}{28}{figure.74}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces A comparison of the Basel Face Model parameters. In this plot the fits of egger and the FCN of Figure \ref  {fig:chap3:zlabelsandfits_setting2} and the fit with the combined mask \ref  {fig:chap4:bsp1_fit_combined} are compared. For each parameter, all dimensions are considered. With the combined segmentation, the fit is a tiny bit better than with the segmentation of Egger et al. alone.}}{29}{figure.75}}
\newlabel{fig:chap4:fit_comparison_2}{{\M@TitleReference {4.6}{A comparison of the Basel Face Model parameters. In this plot the fits of egger and the FCN of Figure \ref  {fig:chap3:zlabelsandfits_setting2} and the fit with the combined mask \ref  {fig:chap4:bsp1_fit_combined} are compared. For each parameter, all dimensions are considered. With the combined segmentation, the fit is a tiny bit better than with the segmentation of Egger et al. alone.}}{29}{A comparison of the Basel Face Model parameters. In this plot the fits of egger and the FCN of Figure \ref {fig:chap3:zlabelsandfits_setting2} and the fit with the combined mask \ref {fig:chap4:bsp1_fit_combined} are compared. For each parameter, all dimensions are considered. With the combined segmentation, the fit is a tiny bit better than with the segmentation of Egger et al. alone}{figure.75}{}}
\newlabel{fig:chap4:fit_comparison_2@cref}{{[figure][6][4]4.6}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces The illuminations of the last example rendered on a sphere. It seems like (as in the previous example) the illumination with the FCN mask is dull and has no specular term (only ambient). Again, the illumination with the combined mask is strongly based on illumination (a).}}{29}{figure.80}}
\newlabel{fig:chap4:bsp2_illumination}{{\M@TitleReference {4.7}{The illuminations of the last example rendered on a sphere. It seems like (as in the previous example) the illumination with the FCN mask is dull and has no specular term (only ambient). Again, the illumination with the combined mask is strongly based on illumination (a).}}{29}{The illuminations of the last example rendered on a sphere. It seems like (as in the previous example) the illumination with the FCN mask is dull and has no specular term (only ambient). Again, the illumination with the combined mask is strongly based on illumination (a)}{figure.80}{}}
\newlabel{fig:chap4:bsp2_illumination@cref}{{[figure][7][4]4.7}{29}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces Egger et al.}}{29}{figure.80}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces FCN}}{29}{figure.80}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces combination}}{29}{figure.80}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces groundtruth}}{29}{figure.80}}
\citation{nirkin2018_faceswap}
\citation{egger_paper}
\citation{egger_paper}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {5}Conclusion}{30}{chapter.81}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Three examples of training images used by Nirkin et al. These are pictures of the recent Janus CS2 dataset. It looks like the face was not turned on any of the faces. The first two images are overlayd with synthetic occlusions. The third one depicts the interface used for semi-supervised labeling.}}{30}{figure.82}}
\newlabel{fig:chap5:train_images}{{\M@TitleReference {5.1}{Three examples of training images used by Nirkin et al. These are pictures of the recent Janus CS2 dataset. It looks like the face was not turned on any of the faces. The first two images are overlayd with synthetic occlusions. The third one depicts the interface used for semi-supervised labeling.}}{30}{Three examples of training images used by Nirkin et al. These are pictures of the recent Janus CS2 dataset. It looks like the face was not turned on any of the faces. The first two images are overlayd with synthetic occlusions. The third one depicts the interface used for semi-supervised labeling}{figure.82}{}}
\newlabel{fig:chap5:train_images@cref}{{[figure][1][5]5.1}{30}}
\newlabel{fig:tm:tm1}{{5.2(a)}{31}{Subfigure 5.2(a)\relax }{subfigure.83}{}}
\newlabel{sub@fig:tm:tm1}{{(a)}{31}{Subfigure 5.2(a)\relax }{subfigure.83}{}}
\newlabel{fig:tm:tm1@cref}{{[subfigure][1][5,2]5.2(a)}{31}}
\newlabel{fig:tm:tm2}{{5.2(b)}{31}{Subfigure 5.2(b)\relax }{subfigure.84}{}}
\newlabel{sub@fig:tm:tm2}{{(b)}{31}{Subfigure 5.2(b)\relax }{subfigure.84}{}}
\newlabel{fig:tm:tm2@cref}{{[subfigure][2][5,2]5.2(b)}{31}}
\newlabel{fig:tm:tm3}{{5.2(c)}{31}{Subfigure 5.2(c)\relax }{subfigure.85}{}}
\newlabel{sub@fig:tm:tm3}{{(c)}{31}{Subfigure 5.2(c)\relax }{subfigure.85}{}}
\newlabel{fig:tm:tm3@cref}{{[subfigure][3][5,2]5.2(c)}{31}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Comparison of the two segmentation ((b) and (c)) of the same facial image (a).}}{31}{figure.86}}
\newlabel{fig:chap5:harry}{{\M@TitleReference {5.2}{Comparison of the two segmentation ((b) and (c)) of the same facial image (a).}}{31}{Comparison of the two segmentation ((b) and (c)) of the same facial image (a)}{figure.86}{}}
\newlabel{fig:chap5:harry@cref}{{[figure][2][5]5.2}{31}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces original}}{31}{figure.86}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces segmentation of Egger et al.}}{31}{figure.86}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces segmentation of FCN}}{31}{figure.86}}
\@writefile{toc}{\vspace  {2em}}
\bibstyle{thesis}
\bibdata{thesis}
\bibcite{BFM2017}{{1}{}{{}}{{}}}
\bibcite{nirkin2018_faceswap}{{2}{}{{}}{{}}}
\bibcite{mcculloch}{{3}{}{{}}{{}}}
\bibcite{jlong}{{4}{}{{}}{{}}}
\bibcite{ksimonyan}{{5}{}{{}}{{}}}
\bibcite{grundmann}{{6}{}{{}}{{}}}
\bibcite{egger_paper}{{7}{}{{}}{{}}}
\bibcite{Uricar}{{8}{}{{}}{{}}}
\bibcite{SaitoEtAl}{{9}{}{{}}{{}}}
\bibcite{MorelForster}{{10}{}{{}}{{}}}
\bibcite{cofw}{{11}{}{{}}{{}}}
\bibcite{LFW_dataset}{{12}{}{{}}{{}}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{32}{section*.88}}
\bibcite{parametric}{{13}{}{{}}{{}}}
\bibcite{BlanzVetter}{{14}{}{{}}{{}}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {appendix}{\chapternumberline {A}Appendix}{34}{appendix.89}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}COFW-Images and Fits}{34}{section.90}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.1}{\ignorespaces The additional images of Figure \ref  {fig:chap2:COFW_Fits}. In each tuple the first plot shows the fit with the mask of egger et al. and the second plot is made with the segmentation of the FCN.}}{34}{figure.91}}
\newlabel{fig:chap2:COFW_Fits_Appendix}{{\M@TitleReference {A.1}{The additional images of Figure \ref  {fig:chap2:COFW_Fits}. In each tuple the first plot shows the fit with the mask of egger et al. and the second plot is made with the segmentation of the FCN.}}{34}{The additional images of Figure \ref {fig:chap2:COFW_Fits}. In each tuple the first plot shows the fit with the mask of egger et al. and the second plot is made with the segmentation of the FCN}{figure.91}{}}
\newlabel{fig:chap2:COFW_Fits_Appendix@cref}{{[figure][1][2147483647,1]A.1}{34}}
\@writefile{toc}{\contentsline {section}{\numberline {A.2}Datasets other than Hands(which are shown in the thesis)}{34}{section.92}}
\@writefile{toc}{\vspace  {2em}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{Declaration on Scientific Integrity}{49}{appendix*.93}}
\newlabel{DeclarationOfAuthorship}{{\M@TitleReference {5}{Declaration on Scientific Integrity}}{49}{Declaration on Scientific Integrity}{appendix*.93}{}}
\newlabel{DeclarationOfAuthorship@cref}{{[chapter][5][]5}{49}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\memsetcounter{lastsheet}{54}
\memsetcounter{lastpage}{49}
